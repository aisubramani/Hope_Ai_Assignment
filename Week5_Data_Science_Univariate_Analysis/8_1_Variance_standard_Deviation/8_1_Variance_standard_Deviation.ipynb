{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e2b964-03f8-4bfb-a0e3-afbaf3dbe649",
   "metadata": {},
   "source": [
    "# Class function for QuanQual, UnivariateTable, replace_outliers, FreqTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b383a7f9-9bc0-40b4-a57f-ed406c6618da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#---univariate Class----\n",
    "class myunivariate():\n",
    "    #QuanQual list split\n",
    "    def QuanQual(df):\n",
    "        quan=[x for x in df if df[x].dtype!=object]\n",
    "        qual=[x for x in df if df[x].dtype==object]\n",
    "        return quan,qual\n",
    "    #--------------------------------------------------\n",
    "    #create New Table for central Tendency & descriptive\n",
    "   #create New Table for central Tendency & descriptive#create New Table for central Tendency & descriptive\n",
    "    def UnivariateTable(df,num_cals):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        descriptive=pd.DataFrame(index=[\"Mean\",\"Median\",\"Mode\",\n",
    "                                        \"Min\",\"Q1-25%\",\"Q2-50%\",\"Q3-75%\",\"Max\",\n",
    "                                       \"IQR\",\"1.5-Rule\",\"Lower-Bound\",\"Upper-Bound\",\n",
    "                                       \"Skew\",\"Kurtosis\",\n",
    "                                       \"Variance\",\"Std\"]\n",
    "                                 ,columns=num_cals)\n",
    "        for cal in num_cals:\n",
    "            #print(cal)\n",
    "            descriptive.loc[\"Mean\", cal] = round(df[cal].mean(), 2)\n",
    "            descriptive.loc[\"Median\", cal] = df[cal].median()\n",
    "            descriptive.loc[\"Mode\", cal] = round(df[cal].mode()[0], 2)\n",
    "            descriptive.loc[\"Min\",cal]=df.describe().loc['min',cal]\n",
    "            descriptive.loc[\"Q1-25%\",cal]=df.describe().loc['25%',cal]\n",
    "            descriptive.loc[\"Q2-50%\",cal]=df.describe().loc['50%',cal]\n",
    "            descriptive.loc[\"Q3-75%\",cal]=df.describe().loc['75%',cal]\n",
    "            descriptive.loc[\"Max\",cal]=df.describe().loc['max',cal]\n",
    "            descriptive.loc[\"IQR\",cal]=descriptive.loc[\"Q3-75%\",cal]-descriptive.loc[\"Q1-25%\",cal]\n",
    "            descriptive.loc[\"1.5-Rule\",cal]=1.5*descriptive.loc[\"IQR\",cal]\n",
    "            descriptive.loc[\"Lower-Bound\",cal]=descriptive.loc[\"Q1-25%\",cal]-descriptive.loc[\"1.5-Rule\",cal]\n",
    "            descriptive.loc[\"Upper-Bound\",cal]=descriptive.loc[\"Q3-75%\",cal]+descriptive.loc[\"1.5-Rule\",cal]\n",
    "            descriptive.loc[\"Skew\",cal]=round(descriptive[cal].skew(), 2)\n",
    "            descriptive.loc[\"Kurtosis\",cal]=round(descriptive[cal].kurtosis(), 2)\n",
    "            descriptive.loc[\"Variance\",cal]=round(descriptive[cal].var(), 2)\n",
    "            descriptive.loc[\"Std\",cal]=round(descriptive[cal].std(), 2)\n",
    "        \n",
    "        #return descriptive\n",
    "        \n",
    "        print(\"\\n-------------- Outlier info --------------\\n\")\n",
    "        lesser=[]\n",
    "        greater=[]\n",
    "        for cal in num_cals:\n",
    "            if descriptive.loc[\"Min\",cal]<descriptive.loc[\"Lower-Bound\",cal]:\n",
    "                lesser.append(cal)\n",
    "                print(f\"Lower outlier in :'{cal}' value :\", descriptive.loc[\"Min\",cal])\n",
    "            if descriptive.loc[\"Max\",cal]>descriptive.loc[\"Upper-Bound\",cal]:\n",
    "                greater.append(cal)\n",
    "                print(f\"Upper outlier in :'{cal}' value :\", descriptive.loc[\"Max\",cal])\n",
    "        print(\"Lesser outlier :\",lesser,\"\\nGreater outlier:\",greater)\n",
    "        print(\"\\n-------------- Univariate Table  --------------\\n\")\n",
    "        return descriptive       \n",
    "    #---------------------------------------------------\n",
    "    #---------------------------------------------------\n",
    "    # Function to replace outliers using np.percentile\n",
    "    def replace_outliers(df):\n",
    "        print(\"\\n-------------- Outliers Replaced info --------------\\n\")\n",
    "        for col in df.select_dtypes(exclude=\"object\").columns:\n",
    "            # Q1 (25th percentile) and Q3 (75th percentile)\n",
    "            #dropna() removes missing values (NaN) before calculating, \n",
    "            #Q1 = df[col].quantile(0.25) # other way in panda calculate Q1, Q2\n",
    "            #Q3 = df[col].quantile(0.75)\n",
    "            Q1 = np.percentile(df[col].dropna(), 25)\n",
    "            Q3 = np.percentile(df[col].dropna(), 75)\n",
    "            IQR = Q3 - Q1\n",
    "    \n",
    "            # Bounds\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "            # Replace lower outliers with lower bound\n",
    "            df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "            \n",
    "            # Replace higher outliers with upper bound\n",
    "            df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "            print(f\"{col}: Outliers replaced → lower < {lower_bound:.2f}, upper > {upper_bound:.2f}\")\n",
    "        \n",
    "        return df\n",
    "    #---------------------------------------------------\n",
    "    #create Function for freqtable\n",
    "    def FreqTable(df,column_name):\n",
    "        print(f\"\\n---- Frequency Table for '{column_name}'------\\n\")\n",
    "        freqtable = df[column_name].value_counts().reset_index()\n",
    "        # Rename columns\n",
    "        freqtable.columns = [\"Unique_Values\", \"Frequency\"]\n",
    "        # Calculate relative frequency\n",
    "        freqtable[\"Relative_Frequency\"] = freqtable[\"Frequency\"] / freqtable[\"Frequency\"].sum()\n",
    "        # Cumulative relative frequency\n",
    "        freqtable[\"Cumulative_Rel_Freq\"] = freqtable[\"Relative_Frequency\"].cumsum()\n",
    "        # Optional: sort by Frequency\n",
    "        #freqtable = freqtable.sort_values(by=\"Frequency\").reset_index(drop=True)\n",
    "        return freqtable \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355f1b9-7006-48ae-abcd-d6af68272851",
   "metadata": {},
   "source": [
    "# Call Class and Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d555b435-a3f8-439d-a42f-0f04b0f3f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssc_p', 'hsc_p', 'degree_p', 'etest_p', 'mba_p', 'salary']\n"
     ]
    }
   ],
   "source": [
    "#from my_class_univariate import myunivariate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_csv(\"Placement.csv\")\n",
    "\n",
    "# Get quantitative and qualitative columns\n",
    "quan, qual = myunivariate.QuanQual(dataset)\n",
    "quan.remove(\"sl_no\")\n",
    "print(quan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a61106a-955f-4936-a557-0e3f264627b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- Outlier info --------------\n",
      "\n",
      "Lower outlier in :'hsc_p' value : 37.0\n",
      "Upper outlier in :'hsc_p' value : 97.7\n",
      "Upper outlier in :'degree_p' value : 91.0\n",
      "Upper outlier in :'salary' value : 940000.0\n",
      "Lesser outlier : ['hsc_p'] \n",
      "Greater outlier: ['hsc_p', 'degree_p', 'salary']\n",
      "\n",
      "-------------- Univariate Table  --------------\n",
      "\n",
      "              ssc_p    hsc_p degree_p  etest_p   mba_p              salary\n",
      "Mean           67.3    66.33    66.37     72.1   62.28           288655.41\n",
      "Median         67.0     65.0     66.0     71.0    62.0            265000.0\n",
      "Mode           62.0     63.0     65.0     60.0    56.7            300000.0\n",
      "Min           40.89     37.0     50.0     50.0   51.21            200000.0\n",
      "Q1-25%         60.6     60.9     61.0     60.0  57.945            240000.0\n",
      "Q2-50%         67.0     65.0     66.0     71.0    62.0            265000.0\n",
      "Q3-75%         75.7     73.0     72.0     83.5  66.255            300000.0\n",
      "Max            89.4     97.7     91.0     98.0   77.89            940000.0\n",
      "IQR            15.1     12.1     11.0     23.5    8.31             60000.0\n",
      "1.5-Rule      22.65    18.15     16.5    35.25  12.465             90000.0\n",
      "Lower-Bound   37.95    42.75     44.5    24.75   45.48            150000.0\n",
      "Upper-Bound   98.35    91.15     88.5   118.75   78.72            390000.0\n",
      "Skew          -0.31    -0.38    -0.82     0.28   -1.25                 2.4\n",
      "Kurtosis      -0.51    -0.57    -0.33    -0.14   -0.17                6.51\n",
      "Variance     996.93  1020.33   966.29  1225.89   805.2  53994662105.190002\n",
      "Std          246.33   252.58   238.53   304.24   198.0  13941297468.969999\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics with outliers\n",
    "desc = myunivariate.UnivariateTable(dataset,quan)\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3905b235-4dc4-4581-829b-0478412c66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- Outliers Replaced info --------------\n",
      "\n",
      "sl_no: Outliers replaced → lower < -106.00, upper > 322.00\n",
      "ssc_p: Outliers replaced → lower < 37.95, upper > 98.35\n",
      "hsc_p: Outliers replaced → lower < 42.75, upper > 91.15\n",
      "degree_p: Outliers replaced → lower < 44.50, upper > 88.50\n",
      "etest_p: Outliers replaced → lower < 24.75, upper > 118.75\n",
      "mba_p: Outliers replaced → lower < 45.48, upper > 78.72\n",
      "salary: Outliers replaced → lower < 150000.00, upper > 390000.00\n"
     ]
    }
   ],
   "source": [
    "# Replace outliers\n",
    "cleaned_dataset = myunivariate.replace_outliers(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8ce1fb0-bf81-4d34-8041-dc257b4c982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------- Outlier info --------------\n",
      "\n",
      "Lesser outlier : [] \n",
      "Greater outlier: []\n",
      "\n",
      "-------------- Univariate Table  --------------\n",
      "\n",
      "              ssc_p   hsc_p degree_p  etest_p   mba_p         salary\n",
      "Mean           67.3   66.33    66.36     72.1   62.28      277648.65\n",
      "Median         67.0    65.0     66.0     71.0    62.0       265000.0\n",
      "Mode           62.0    63.0     65.0     60.0    56.7       300000.0\n",
      "Min           40.89   42.75     50.0     50.0   51.21       200000.0\n",
      "Q1-25%         60.6    60.9     61.0     60.0  57.945       240000.0\n",
      "Q2-50%         67.0    65.0     66.0     71.0    62.0       265000.0\n",
      "Q3-75%         75.7    73.0     72.0     83.5  66.255       300000.0\n",
      "Max            89.4   91.15     88.5     98.0   77.89       390000.0\n",
      "IQR            15.1    12.1     11.0     23.5    8.31        60000.0\n",
      "1.5-Rule      22.65   18.15     16.5    35.25  12.465        90000.0\n",
      "Lower-Bound   37.95   42.75     44.5    24.75   45.48       150000.0\n",
      "Upper-Bound   98.35   91.15     88.5   118.75   78.72       390000.0\n",
      "Skew          -0.31   -0.58    -0.88     0.28   -1.25           -0.4\n",
      "Kurtosis      -0.51   -0.47    -0.32    -0.14   -0.17           -0.5\n",
      "Variance     996.93  967.29   951.24  1225.89   805.2  17024293801.0\n",
      "Std          246.33  238.91    234.7   304.24   198.0  4395599765.99\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics without outlier\n",
    "desc = myunivariate.UnivariateTable(cleaned_dataset,quan)\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82d36e06-cf52-4a5d-8e80-c30a0d38b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency table for all Quan\n",
    "#freq = myunivariate.FreqTable(cleaned_dataset,\"ssc_p\")\n",
    "#print(freq)\n",
    "for x in quan:\n",
    "    freq = myunivariate.FreqTable(cleaned_dataset,x)\n",
    "    print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683fce82-82df-4ec0-a4c4-a5d6aaa80d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
