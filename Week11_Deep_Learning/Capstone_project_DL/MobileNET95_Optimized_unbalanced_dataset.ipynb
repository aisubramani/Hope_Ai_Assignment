{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdf9ff2-9965-4869-a0cf-46672fe7d85e",
   "metadata": {},
   "source": [
    "# MobileNetV3 Performances - Before imbalanced Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891ccbda-1464-4dcf-9757-d0b756072697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Classes: ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "Class counts: Counter({3: 827, 0: 826, 1: 822, 2: 395})\n",
      "\n",
      "Epoch 1/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.9521 | Train Acc: 62.18%\n",
      "Val Loss: 1.3179 | Val Acc: 46.45%\n",
      " Best model saved!\n",
      " Time: 258.06 sec\n",
      "\n",
      "Epoch 2/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.7659 | Train Acc: 71.48%\n",
      "Val Loss: 1.6726 | Val Acc: 40.10%\n",
      " No improvement, patience left: 4\n",
      " Time: 273.11 sec\n",
      "\n",
      "Epoch 3/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.6756 | Train Acc: 75.28%\n",
      "Val Loss: 1.8475 | Val Acc: 41.12%\n",
      " No improvement, patience left: 3\n",
      " Time: 263.65 sec\n",
      "\n",
      "Epoch 4/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.6461 | Train Acc: 76.64%\n",
      "Val Loss: 1.1847 | Val Acc: 58.63%\n",
      " Best model saved!\n",
      " Time: 238.42 sec\n",
      "\n",
      "Epoch 5/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.6276 | Train Acc: 77.92%\n",
      "Val Loss: 0.8912 | Val Acc: 68.53%\n",
      " Best model saved!\n",
      " Time: 193.62 sec\n",
      "\n",
      "Epoch 6/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.6237 | Train Acc: 78.04%\n",
      "Val Loss: 0.8621 | Val Acc: 69.80%\n",
      " Best model saved!\n",
      " Time: 191.65 sec\n",
      "\n",
      "Epoch 7/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.6061 | Train Acc: 78.26%\n",
      "Val Loss: 0.7961 | Val Acc: 72.84%\n",
      " Best model saved!\n",
      " Time: 211.11 sec\n",
      "\n",
      "Epoch 8/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.6170 | Train Acc: 78.86%\n",
      "Val Loss: 1.0803 | Val Acc: 63.45%\n",
      " No improvement, patience left: 4\n",
      " Time: 200.92 sec\n",
      "\n",
      "Epoch 9/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5974 | Train Acc: 79.34%\n",
      "Val Loss: 0.8597 | Val Acc: 72.59%\n",
      " No improvement, patience left: 3\n",
      " Time: 197.41 sec\n",
      "\n",
      "Epoch 10/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5692 | Train Acc: 79.83%\n",
      "Val Loss: 0.9375 | Val Acc: 67.01%\n",
      " No improvement, patience left: 2\n",
      " Time: 225.42 sec\n",
      "\n",
      "Epoch 11/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5758 | Train Acc: 80.35%\n",
      "Val Loss: 0.8102 | Val Acc: 70.30%\n",
      " No improvement, patience left: 1\n",
      " Time: 255.15 sec\n",
      "\n",
      "Epoch 12/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5585 | Train Acc: 81.62%\n",
      "Val Loss: 0.6989 | Val Acc: 75.38%\n",
      " Best model saved!\n",
      " Time: 282.11 sec\n",
      "\n",
      "Epoch 13/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5707 | Train Acc: 80.76%\n",
      "Val Loss: 0.8637 | Val Acc: 72.84%\n",
      " No improvement, patience left: 4\n",
      " Time: 273.97 sec\n",
      "\n",
      "Epoch 14/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5730 | Train Acc: 81.15%\n",
      "Val Loss: 0.8302 | Val Acc: 72.84%\n",
      " No improvement, patience left: 3\n",
      " Time: 270.45 sec\n",
      "\n",
      "Epoch 15/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5510 | Train Acc: 81.58%\n",
      "Val Loss: 0.7741 | Val Acc: 74.87%\n",
      " No improvement, patience left: 2\n",
      " Time: 290.44 sec\n",
      "\n",
      "Epoch 16/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5595 | Train Acc: 81.06%\n",
      "Val Loss: 0.8529 | Val Acc: 72.59%\n",
      " No improvement, patience left: 1\n",
      " Time: 282.38 sec\n",
      "\n",
      "Epoch 17/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5231 | Train Acc: 82.40%\n",
      "Val Loss: 0.7247 | Val Acc: 75.89%\n",
      " Best model saved!\n",
      " Time: 276.51 sec\n",
      "\n",
      "Epoch 18/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5329 | Train Acc: 82.05%\n",
      "Val Loss: 0.8691 | Val Acc: 72.34%\n",
      " No improvement, patience left: 4\n",
      " Time: 282.74 sec\n",
      "\n",
      "Epoch 19/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5259 | Train Acc: 82.55%\n",
      "Val Loss: 0.7421 | Val Acc: 74.11%\n",
      " No improvement, patience left: 3\n",
      " Time: 286.15 sec\n",
      "\n",
      "Epoch 20/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5343 | Train Acc: 81.89%\n",
      "Val Loss: 0.7050 | Val Acc: 76.14%\n",
      " Best model saved!\n",
      " Time: 284.21 sec\n",
      "\n",
      "Epoch 21/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5155 | Train Acc: 82.15%\n",
      "Val Loss: 0.7633 | Val Acc: 72.34%\n",
      " No improvement, patience left: 4\n",
      " Time: 291.06 sec\n",
      "\n",
      "Epoch 22/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5038 | Train Acc: 83.51%\n",
      "Val Loss: 0.6159 | Val Acc: 78.93%\n",
      " Best model saved!\n",
      " Time: 341.79 sec\n",
      "\n",
      "Epoch 23/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5177 | Train Acc: 82.70%\n",
      "Val Loss: 0.6118 | Val Acc: 78.43%\n",
      " No improvement, patience left: 4\n",
      " Time: 22450.22 sec\n",
      "\n",
      "Epoch 24/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5180 | Train Acc: 82.60%\n",
      "Val Loss: 0.6381 | Val Acc: 77.92%\n",
      " No improvement, patience left: 3\n",
      " Time: 265.32 sec\n",
      "\n",
      "Epoch 25/25\n",
      "---------------------------------------\n",
      "Train Loss: 0.5173 | Train Acc: 82.97%\n",
      "Val Loss: 0.6729 | Val Acc: 76.40%\n",
      " No improvement, patience left: 2\n",
      " Time: 269.75 sec\n",
      "\n",
      " Training Completed!\n",
      "Best Model Saved As: best_mobilenetv3_mri.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from collections import Counter\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DEVICE\n",
    "# ------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DATA PATH\n",
    "# ------------------------------------------------------------\n",
    "train_dir = \"mri_dataset_images/train\"\n",
    "val_dir = \"mri_dataset_images/test\"\n",
    "\n",
    "classes = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# AUGMENTATION (STRONG)\n",
    "# ------------------------------------------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.25, contrast=0.25),\n",
    "    transforms.RandomAffine(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# DATASET + LOADER\n",
    "# ------------------------------------------------------------\n",
    "train_ds = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_ds = datasets.ImageFolder(val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CLASS WEIGHTS (FIX FOR IMBALANCED DATA)\n",
    "# ------------------------------------------------------------\n",
    "class_counts = Counter(train_ds.targets)\n",
    "print(\"Class counts:\", class_counts)\n",
    "\n",
    "weights = []\n",
    "for i in range(len(classes)):\n",
    "    weights.append(1.0 / class_counts[i])\n",
    "\n",
    "weights = torch.tensor(weights).float().to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MIXUP FUNCTION\n",
    "# ------------------------------------------------------------\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LOAD MobileNetV3-Large + FINE TUNE\n",
    "# ------------------------------------------------------------\n",
    "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze all base layers\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last 3 blocks\n",
    "for param in model.features[-3:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Replace classifier (INCREASE DROPOUT)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(model.classifier[0].in_features, 1024),\n",
    "    nn.Hardswish(),\n",
    "    nn.Dropout(0.4),   # increased dropout to reduce overfitting\n",
    "    nn.Linear(1024, 4)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# OPTIMIZER\n",
    "# ------------------------------------------------------------\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TRAINING FUNCTION (WITH TRAIN ACCURACY)\n",
    "# ------------------------------------------------------------\n",
    "def train_model(model, criterion, optimizer, dataloaders,\n",
    "                num_epochs=25, patience=5):\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "    no_improve = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start = time.time()\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "        print(\"---------------------------------------\")\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0\n",
    "            running_corrects = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # MIXUP only during training\n",
    "                if phase == \"train\":\n",
    "                    inputs, targets_a, targets_b, lam = mixup_data(inputs, labels)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # Approx accuracy for Mixup\n",
    "                    running_corrects += (lam * (preds == targets_a).sum().item()\n",
    "                                        + (1 - lam) * (preds == targets_b).sum().item())\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        running_corrects += (preds == labels).sum().item()\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                total_samples += inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc = running_corrects / total_samples\n",
    "\n",
    "            if phase == \"train\":\n",
    "                print(f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc*100:.2f}%\")\n",
    "            else:\n",
    "                print(f\"Val Loss: {epoch_loss:.4f} | Val Acc: {epoch_acc*100:.2f}%\")\n",
    "\n",
    "                # Save best model\n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_wts = copy.deepcopy(model.state_dict())\n",
    "                    torch.save(best_wts, \"best_mobilenetv3_mri.pth\")\n",
    "                    print(\" Best model saved!\")\n",
    "                    no_improve = 0\n",
    "                else:\n",
    "                    no_improve += 1\n",
    "                    print(f\" No improvement, patience left: {patience - no_improve}\")\n",
    "\n",
    "        print(f\" Time: {time.time() - start:.2f} sec\")\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            print(\"\\n Early Stopping Activated!\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n Training Completed!\")\n",
    "    print(\"Best Model Saved As: best_mobilenetv3_mri.pth\")\n",
    "\n",
    "    model.load_state_dict(best_wts)\n",
    "    return model\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# TRAIN MODEL\n",
    "# ------------------------------------------------------------\n",
    "model = train_model(model, criterion, optimizer, dataloaders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b94ad1c-c17b-4faf-a789-37c925bef7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
