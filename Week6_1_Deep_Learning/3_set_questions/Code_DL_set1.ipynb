{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9acaf04-7f2a-4563-a7f8-8d81600586a7",
   "metadata": {},
   "source": [
    "# Coding DL set1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99116ef-a19b-4e59-85df-f186c09672f1",
   "metadata": {},
   "source": [
    "Question 1: Image Preprocessing for Inference (PyTorch)\n",
    "Problem: Write a function to load an image and preprocess it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c74e2a-dc83-40e7-a554-713bd6f12b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed tensor shape: torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads an image and preprocesses it for inference using PyTorch.\n",
    "    Returns a tensor of shape (1, 3, H, W).\n",
    "    \"\"\"\n",
    "\n",
    "    # Define transforms (resize → center crop → convert to tensor → normalize)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),  # Converts image to [C, H, W] in range [0,1]\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],  # Standard ImageNet means\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Apply transforms\n",
    "    img_tensor = preprocess(image)\n",
    "\n",
    "    # Add batch dimension → (1, 3, 224, 224)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "# Example usage\n",
    "tensor = preprocess_image(\"tiger.jpg\")\n",
    "print(\"Preprocessed tensor shape:\", tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb27e970-e6f3-47b4-81a4-9ac40525fffd",
   "metadata": {},
   "source": [
    "Question 2: Predict on New Image with a Trained Model\n",
    "Problem: Perform prediction and get the class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38aefc6d-6edb-484e-97d0-5264871cac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions...\n",
      "\n",
      "cat1.jpg  ->  Predicted: Cat\n",
      "dog1.jpg  ->  Predicted: Dog\n",
      "dog4.jpg  ->  Predicted: Dog\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import required libraries\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "# Step 2: Preprocess image function\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Load and preprocess a single image for inference.\"\"\"\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),          # Resize image\n",
    "        transforms.ToTensor(),                  # Convert to tensor\n",
    "        transforms.Normalize(                   # Normalize tensor\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    img = Image.open(image_path).convert(\"RGB\") # Load image\n",
    "    return preprocess(img).unsqueeze(0)         # Add batch dimension\n",
    "\n",
    "\n",
    "# Step 3: Define a simple demo model\n",
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"Simple model for demo.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(3 * 224 * 224, 2)  # 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)              # Flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# Step 4: Prediction function\n",
    "def predict_image(model, image_tensor, class_names):\n",
    "    \"\"\"Predict label from processed image.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return class_names[predicted.item()]\n",
    "\n",
    "\n",
    "# Step 5: Main script\n",
    "if __name__ == \"__main__\":\n",
    "    model = SimpleModel()        # Create model\n",
    "    model.eval()                 # Set model to eval mode\n",
    "\n",
    "    class_names = [\"Cat\", \"Dog\"] # Class labels\n",
    "    folder = \"sample_image/input_image\"   # Input folder path\n",
    "\n",
    "    print(\"Running predictions...\\n\")\n",
    "\n",
    "    # Step 6: Loop through images and predict\n",
    "    for f in os.listdir(folder):\n",
    "        if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):  # Accept image formats\n",
    "            img_path = os.path.join(folder, f)\n",
    "            img_tensor = preprocess_image(img_path)         # Preprocess\n",
    "            label = predict_image(model, img_tensor, class_names)  # Predict\n",
    "            print(f\"{f}  ->  Predicted: {label}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca19192d-078d-4c6d-ac47-b57d11630d49",
   "metadata": {},
   "source": [
    "Question 3: Build a CNN to classify CIFAR-10 images (>60% accuracy)\n",
    "\n",
    "This CNN will easily reach 65–70% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cabc3284-29da-4818-bca9-7a9b236374cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started...\n",
      "\n",
      "Epoch 1, Loss: 1010.58\n",
      "Epoch 2, Loss: 720.50\n",
      "Epoch 3, Loss: 588.19\n",
      "Epoch 4, Loss: 490.27\n",
      "Epoch 5, Loss: 404.26\n",
      "\n",
      "Test Accuracy: 72.31%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Step 2: Define transforms (normalize CIFAR-10)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        (0.4914, 0.4822, 0.4465),\n",
    "        (0.2470, 0.2435, 0.2616)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Step 3: Load CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Step 4: Create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Step 5: Build CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # FIXED\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # FIXED\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)  # 10 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Step 6: Initialize model, loss, optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 7: Training loop\n",
    "print(\"\\nTraining started...\\n\")\n",
    "\n",
    "for epoch in range(5):  # 5 epochs gives 60–70% accuracy\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss:.2f}\")\n",
    "\n",
    "# Step 8: Evaluate accuracy on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92a999-026e-45c1-8203-34065e43f1b5",
   "metadata": {},
   "source": [
    "Question 4: Identify Overfitting + Fix it using Dropout & Early Stopping\n",
    "\n",
    "(using MNIST dataset)\n",
    "\n",
    "This version is easy, exam-ready, and fully working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5077484d-2193-46fd-8e9a-c72e7c1ca407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started...\n",
      "\n",
      "Epoch 1: Train Loss = 328.85,  Val Loss = 21.42,  Val Acc = 95.64%\n",
      "Epoch 2: Train Loss = 146.18,  Val Loss = 16.29,  Val Acc = 96.85%\n",
      "Epoch 3: Train Loss = 110.26,  Val Loss = 13.62,  Val Acc = 97.25%\n",
      "Epoch 4: Train Loss = 91.06,  Val Loss = 12.70,  Val Acc = 97.51%\n",
      "Epoch 5: Train Loss = 78.04,  Val Loss = 11.55,  Val Acc = 97.86%\n",
      "Epoch 6: Train Loss = 69.19,  Val Loss = 11.14,  Val Acc = 97.86%\n",
      "Epoch 7: Train Loss = 64.39,  Val Loss = 11.06,  Val Acc = 97.95%\n",
      "Epoch 8: Train Loss = 55.88,  Val Loss = 10.79,  Val Acc = 98.03%\n",
      "Epoch 9: Train Loss = 54.10,  Val Loss = 10.05,  Val Acc = 98.23%\n",
      "Epoch 10: Train Loss = 50.07,  Val Loss = 10.41,  Val Acc = 98.23%\n",
      " → No improvement. Early stopping in 2 epochs.\n",
      "Epoch 11: Train Loss = 44.64,  Val Loss = 10.67,  Val Acc = 98.26%\n",
      " → No improvement. Early stopping in 1 epochs.\n",
      "Epoch 12: Train Loss = 42.98,  Val Loss = 9.99,  Val Acc = 98.25%\n",
      "Epoch 13: Train Loss = 43.77,  Val Loss = 10.53,  Val Acc = 98.14%\n",
      " → No improvement. Early stopping in 2 epochs.\n",
      "Epoch 14: Train Loss = 37.69,  Val Loss = 10.16,  Val Acc = 98.33%\n",
      " → No improvement. Early stopping in 1 epochs.\n",
      "Epoch 15: Train Loss = 37.41,  Val Loss = 10.68,  Val Acc = 98.19%\n",
      " → No improvement. Early stopping in 0 epochs.\n",
      "\n",
      "Early stopping activated!\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Step 2: Load MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./mnist', train=True, download=True, transform=transform\n",
    ")\n",
    "val_dataset = torchvision.datasets.MNIST(\n",
    "    root='./mnist', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Step 3: Build a model with DROPOUT to reduce overfitting\n",
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),         # Dropout added\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),         # Dropout added\n",
    "\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Step 4: Initialize model, loss, optimizer\n",
    "model = MNISTModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 5: Early Stopping Setup\n",
    "best_val_loss = float('inf')\n",
    "patience = 3          # Stop if no improvement for 3 epochs\n",
    "patience_counter = 0\n",
    "\n",
    "# Step 6: Training loop with validation + early stopping\n",
    "print(\"\\nTraining started...\\n\")\n",
    "\n",
    "for epoch in range(20):  # Max 20 epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Step 7: Compute validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.2f},  \"\n",
    "          f\"Val Loss = {val_loss:.2f},  Val Acc = {val_acc:.2f}%\")\n",
    "\n",
    "    # Step 8: Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0   # Reset\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\" → No improvement. Early stopping in {patience - patience_counter} epochs.\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"\\nEarly stopping activated!\")\n",
    "            break\n",
    "\n",
    "print(\"\\nTraining complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b42e68-0a39-4e54-83e4-044b2f479c68",
   "metadata": {},
   "source": [
    "Question 5: Transfer Learning with Pretrained VGG16 (Cats vs Dogs)\n",
    "Problem: Use VGG16 for binary classification with fine-tuning\n",
    "Collect dataset from the below sites or any other,\n",
    "Kaggle Datasets : https://www.kaggle.com/datasets\n",
    "Google Dataset Search : https://datasetsearch.research.google.com\n",
    "Papers with Code – Datasets :https://paperswithcode.com/datasets\n",
    "Roboflow Universe : https://universe.roboflow.com\n",
    "ImageNet :  https://image-net.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0df72c1d-f4a1-4914-b87d-2f6b7a3aae9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\15016/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started...\n",
      "\n",
      "Epoch 1, Train Loss: 3.24\n",
      "Validation Accuracy: 95.71%\n",
      "\n",
      "Epoch 2, Train Loss: 0.15\n",
      "Validation Accuracy: 98.57%\n",
      "\n",
      "Epoch 3, Train Loss: 0.01\n",
      "Validation Accuracy: 97.14%\n",
      "\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Download Link:\n",
    "# https://www.kaggle.com/datasets/samuelcortinhas/cats-and-dogs-image-classification\n",
    "\n",
    "# Step 1: Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# Step 2: Define image transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],   # VGG16 normalization\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# Step 3: Load dataset (Cats vs Dogs)\n",
    "train_dir = \"sample_image/train\"   #  path images\n",
    "val_dir   = \"sample_image/test\"    #  path images\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data   = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 4: Load pretrained VGG16\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Step 5: Freeze all convolutional layers\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Step 6: Replace classifier (fine-tuning)\n",
    "model.classifier[6] = nn.Linear(4096, 2)   # 2 classes: cat, dog\n",
    "\n",
    "# Step 7: Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n",
    "\n",
    "# Step 8: Training loop\n",
    "print(\"\\nTraining started...\\n\")\n",
    "\n",
    "for epoch in range(3):   # 3 epochs is enough for 90%+\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss:.2f}\")\n",
    "\n",
    "    # Step 9: Evaluate accuracy on validation set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\\n\")\n",
    "\n",
    "# Step 10: Save the fine-tuned model\n",
    "torch.save(model.state_dict(), \"vgg16_cats_dogs.pth\")\n",
    "print(\"Model saved successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aeedb-046a-46f2-b1b3-dd832df49739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
